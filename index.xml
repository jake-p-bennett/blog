<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>Jake&#39;s Blog</title>
<link>https://jake-p-bennett.github.io/blog/</link>
<atom:link href="https://jake-p-bennett.github.io/blog/index.xml" rel="self" type="application/rss+xml"/>
<description>Data science portfolio featuring projects in sports analytics, machine learning, and statistical modeling.</description>
<generator>quarto-1.8.25</generator>
<lastBuildDate>Wed, 11 Feb 2026 08:00:00 GMT</lastBuildDate>
<item>
  <title>Jarvis, Who’s the Best Scorer in the NBA?</title>
  <dc:creator>Jake Bennett</dc:creator>
  <link>https://jake-p-bennett.github.io/blog/posts/points-plus/</link>
  <description><![CDATA[ 





<p>While I have integrated some AI tools into my everyday life, I have always found the hype around <a href="https://en.wikipedia.org/wiki/Vibe_coding">vibe coding</a> to be overblown. I have used LLMs to generate code, but whenever I’ve tried to build a whole app or website, it’s failed. For example, a month ago I tried to build a simple NFL playoff bracket that my friends and I could fill out – nothing too complicated, just a bracket set up with certain scoring rules and a leaderboard to see where people stand. I tried to have Anthropic’s <a href="https://www.anthropic.com/news/claude-opus-4-5">Claude Opus 4.5</a> build the website, but it never got off the ground. The clicking mechanisms were broken, the bracket formatting was terrible, and Claude decided to make the scoring variable cumulative – any time you clicked on a team, your score would increase indefinitely, with no way to undo the additions to the score. After trying to prompt Claude to edit the site for an hour or so, I gave up, reaffirmed in my diagnosis that the vibe coding hype was far from reality, even for simple applications.</p>
<p>A few days ago while scrolling through Twitter (I still refuse to call it X), I came across an essay titled <a href="https://x.com/mattshumer_/status/2021256989876109403">Something Big is Happening</a> by Matt Shumer. Generally I don’t read Twitter essays since I find they tend to contain a lot of <a href="https://en.wikipedia.org/wiki/AI_slop">slop</a>, but the algorithm kept insisting on putting this one on my feed. I finally relented and gave it a read after <a href="https://en.wikipedia.org/wiki/Matthew_Yglesias">Matt Yglesias</a> <a href="https://x.com/mattyglesias/status/2021354578407772287">tweeted</a> about it, since Yglesias is far enough removed from the Twitter-tech-echo-chamber.</p>
<p>The essay describes how much frontier models like OpenAI’s ChatGPT and Anthropic’s Claude have advanced over the past year, and even over the past week. Shumer goes on to argue that everyone employed in a type of ‘knowledge work’ (e.g.&nbsp;software engineering, legal work, financial analysis) is at risk of being displaced by AI, and gives recommendations for what to do to shield yourself from this upheaval. I was less interested in Shumer’s macroeconomic predictions<sup>1</sup> and more interested in one of his claims:</p>
<blockquote class="blockquote">
<p>Let me give you an example so you can understand what this actually looks like in practice. I’ll tell the AI: “I want to build this app. Here’s what it should do, here’s roughly what it should look like. Figure out the user flow, the design, all of it.” And it does. It writes tens of thousands of lines of code. Then, and this is the part that would have been unthinkable a year ago, it opens the app itself. It clicks through the buttons. It tests the features. It uses the app the way a person would. If it doesn’t like how something looks or feels, it goes back and changes it, on its own. It iterates, like a developer would, fixing and refining until it’s satisfied.</p>
</blockquote>
<p>Shumer’s essay makes it sound like one can simply ask a supremely competent AI to put together a project, like Tony Stark working with <a href="https://en.wikipedia.org/wiki/J.A.R.V.I.S.">J.A.R.V.I.S.</a> As I mentioned, this was far from my experience with LLMs in the past, even as recently as around a month ago. I was curious to see if models really have gotten that much better since then.</p>
<p>To test this, I decided to see if Anthropic’s newly released <a href="https://www.anthropic.com/news/claude-opus-4-6">Opus 4.6</a> model could build a simple NBA dashboard website that I had been thinking about. My idea was to create a stat called ‘Points+’, which mimics baseball stats like <a href="https://www.mlb.com/glossary/advanced-stats/on-base-plus-slugging-plus">OPS+</a> and <a href="https://www.mlb.com/glossary/advanced-stats/weighted-runs-created-plus">wRC+</a> that account for strength of opponent and scale to the league’s average (centered at 100).</p>
<p>I created a folder on my computer called <code>nba-dashboard/</code>, gave <a href="https://code.claude.com/docs/en/overview">Claude Code</a> access to the folder, and then created a <code>CLAUDE.md</code> file with the following instructions:</p>
<blockquote class="blockquote">
<p>I want you to build an NBA dashboard that tracks a new individual stat called ‘Points+’ for NBA players in the current (2025-2026) NBA season. Points+ is conceptually similar to OPS+ or wRC+ in baseball – it measures points per game compared to league average, adjusting for opponent difficulty (and maybe some other things). So 100 would be an average scorer, and 120 would be a scorer who is 20% better than league average.</p>
<p>The deliverable of this is going to be a website that shows the top 50 players in terms of Points+, and it also will have a search option to look up specific players. Maybe there will be some cool visualizations on there too, if you’re up for it.</p>
<p>You have complete creative freedom in how you build this website. You’ll have to figure out how to obtain the data, how to calculate the stat for each player, and how to build the webpage.</p>
<p>Eventually I’d like this website to automatically download data for each game (maybe the morning of every day) since the NBA season is currently going on. But right now let’s focus on getting the site up and running with an ‘as-of’ date of 2/10/26.</p>
<p>If you have any clarifying questions, you will ask me. You are to test things out as you go. The first time you show me a prototype of the website, I want it to work. I want to be able to click around in it without things breaking.</p>
</blockquote>
<p>Claude worked for 8 minutes, and to my surprise, presented me with a working prototype. It had done everything I asked for: it obtained the data, defined requirements for which players qualify, synthesized the stats into Points+, and created a pretty aesthetically pleasing website. There were a few cosmetic things that I asked it to change (some text was too dark against the background, main summary table was too wide) and a few small technical changes I had it make (the histogram originally did not include the top players, sorting by Points+ showed that ties were handled randomly), but overall it got the website working on the first try. I even had it walk me through how to deploy it to a domain name that I purchased. I wanted to make the site dynamically update with new data every day, and it built that into the site too. The whole process took around 90 minutes.</p>
<p>I’m not sure anyone knows what the future of AI-integrated work looks like. But it does seem that these models are now at a point where they can spin up a personal project with loosely defined requirements extremely quickly. Of course this project is simple – there is no user login, no security concerns, no complicated database management. Even so, I was impressed by the model’s ability to get a working site in front of me so quickly, especially given how miserably my previous attempts at vibe coding had failed.</p>
<p>You can check out the live site at <a href="https://nbapointsplus.com">nbapointsplus.com</a>, and if you’re curious to see the technical approach that Claude took, check out the GitHub <a href="https://github.com/jake-p-bennett/nba-dashboard">repo</a>.</p>
<p><strong>UPDATE (February 13, 2026):</strong> As I mentioned, I want the site to dynamically update with new data every day, and Claude tried to integrate that. It has not worked over the past two days, and I’ve had to manually run the data fetching script and push it to the site. Claude had recommended a <a href="https://github.com/features/actions">GitHub action</a>, but when I asked why it failed, it told me</p>
<blockquote class="blockquote">
<p>The issue is clear: stats.nba.com is timing out all requests from GitHub Actions runners (all 3 attempts hit the 30s timeout). This is a known problem — NBA.com rate-limits/blocks requests from cloud datacenter IPs (like GitHub’s runners), and it works inconsistently.</p>
</blockquote>
<p>Because my IP address isn’t from a cloud datacenter, I don’t get timed out when I make a request from my computer. So Claude’s new recommendation was to set up a scheduled run of the data update with launchd[https://en.wikipedia.org/wiki/Launchd]. That also didn’t work, to which Claude replied,</p>
<blockquote class="blockquote">
<p>The issue is clear. The error log says:</p>
<p>Operation not permitted</p>
<p>The script itself is fine — it ran successfully on Feb 12. But the next scheduled run failed because macOS is blocking it. The shell script doesn’t have execute permission granted by macOS’s security system (this is separate from Unix file permissions).</p>
</blockquote>
<p>So now Claude has wrapped the script in a ‘tiny wrapper binary’, and I’ve granted full-disk access to the wrapper. Supposedly this will allow the script to run tomorrow morning. We shall see!</p>
<p>I think these oversights/omissions show that Claude isn’t perfect at this kind of thing. To be fair, I’m not a software engineer and I don’t know much about GitHub actions, launchd, or script wrappers. If I did, maybe I could have improved my prompts to ensure that these issues didn’t pop up. Asking the right questions and knowing where things might break will continue to be a valuable skill when working with these models.</p>




<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>And as always, it’s worth thinking about if Shumer has anything to gain from hyping AI. His <a href="https://shumer.dev/about">website</a> makes clear that he is the founder of an AI company and invests in other AI companies.↩︎</p></li>
</ol>
</section></div> ]]></description>
  <category>basketball</category>
  <category>sports</category>
  <category>ai</category>
  <guid>https://jake-p-bennett.github.io/blog/posts/points-plus/</guid>
  <pubDate>Wed, 11 Feb 2026 08:00:00 GMT</pubDate>
  <media:content url="https://jake-p-bennett.github.io/blog/posts/points-plus/jarvis.webp" medium="image" type="image/webp"/>
</item>
<item>
  <title>In Basketball, Attention Is Not All You Need</title>
  <dc:creator>Jake Bennett</dc:creator>
  <link>https://jake-p-bennett.github.io/blog/posts/nba-lineups/</link>
  <description><![CDATA[ 





<p>The <a href="https://arxiv.org/abs/1706.03762">attention mechanism</a> revolutionalized the fields of deep learning and natural language processing by introducing a way to model the interactions between words in a nuanced way. I was curious to see if this type of interaction modeling could translate to the chemistry between NBA players. Intuitively it feels like this might work. Nikola Jokic is clearly a dominant player on his own, but surrounding him with lethal shooters and skilled perimiter defenders seems like a better option than pairing him with a ball-dominant defensive liability (like Trae Young). I thought it might also be possible to model lineup matchups in this way, with certain defensive lineups able to stymie certain types of offenses more easily.</p>
<p>In searching for prior work on this topic, I found the <a href="https://arxiv.org/abs/2302.13386">NBA2Vec paper</a>, which showed that player embeddings could capture positional and stylistic similarities. Their approach averaged embeddings across lineups (which I will refer to as the baseline model), losing pairwise interaction information.</p>
<p>I hypothesized that attention mechanisms could do better by: - Using self-attention to model within-team synergies (e.g., pick-and-roll partners) - Using cross-attention to model offensive vs.&nbsp;defensive matchups</p>
<section id="the-data" class="level2">
<h2 class="anchored" data-anchor-id="the-data">The Data</h2>
<p>I used a dataset of play-by-play NBA data from <a href="https://www.kaggle.com/datasets/schmadam97/nba-playbyplay-data-20182019">Kaggle</a> that contains data from the 2015-2022 seasons (only partial data from the 2022 season). The data contained around 4.4 million plays across 9,456 games. To eliminate some noise, I only looked at players with over 100 possessions played, of whom there were 1,181. I wanted the model to predict point differential for the home team.</p>
</section>
<section id="the-models" class="level2">
<h2 class="anchored" data-anchor-id="the-models">The Models</h2>
<p>To start, I mimicked the NBA2Vec methodology<sup>1</sup>, creating a model that learns player embeddings from scratch to predict point differential. Then, I created an attention-based model that uses self-attention for players on the same team, cross-attention for players on different teams, and then sends a possession-weighted average of lineups for each team through a multilayer perceptron to come up with a prediction. Both of these models had an R-squared of around 0, showing that the neural net cannot learn from these random embeddings without some kind of pretraining. To address this issue, I used vectors containing player stats (offensive rating, defensive rating, net rating, possessions, and games played) as embeddings, and tested my original approach both at the player level and at the team level. Attention did not help in this case either, actually making the R-squared worse in each case.</p>
<p>I then decided to try a hybrid approach, using player stats as embeddings but having the model learn residuals. Unfortunately, this method also failed, giving essentially the same R-squared values for both the baseline model and the attention model. Even when adding two more features, player points per 100 possessions<sup>2</sup> and rebounds per 100 possessions, the attention model failed to outperform the baseline model, with both R-squared values refusing to go any higher than 0.2</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Model</th>
<th>Parameters</th>
<th>Test R²</th>
<th>Test RMSE</th>
<th>Win Accuracy</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>EmbeddingsBaseline</td>
<td>83K</td>
<td>0.001</td>
<td>26.7</td>
<td>54.9%</td>
</tr>
<tr class="even">
<td>EmbeddingsAttention</td>
<td>176K</td>
<td>0.000</td>
<td>26.7</td>
<td>56.0%</td>
</tr>
<tr class="odd">
<td>StatsBaseline (team-level)</td>
<td>5K</td>
<td>0.202</td>
<td>12.7</td>
<td>66.5%</td>
</tr>
<tr class="even">
<td>StatsAttention (team-level)</td>
<td>42K</td>
<td>0.193</td>
<td>12.7</td>
<td>66.2%</td>
</tr>
<tr class="odd">
<td>StatsPlayerBaseline</td>
<td>9K</td>
<td>0.201</td>
<td>12.7</td>
<td>65.0%</td>
</tr>
<tr class="even">
<td>StatsPlayerAttention</td>
<td>17K</td>
<td>0.191</td>
<td>12.8</td>
<td>66.1%</td>
</tr>
<tr class="odd">
<td>HybridBaseline</td>
<td>46K</td>
<td>0.203</td>
<td>12.7</td>
<td>65.8%</td>
</tr>
<tr class="even">
<td>HybridAttention</td>
<td>55K</td>
<td>0.199</td>
<td>12.7</td>
<td>65.6%</td>
</tr>
<tr class="odd">
<td>HybridBaseline (rich)</td>
<td>46K</td>
<td>0.203</td>
<td>12.7</td>
<td>66.2%</td>
</tr>
<tr class="even">
<td>HybridAttention (rich)</td>
<td>55K</td>
<td>0.200</td>
<td>12.7</td>
<td>66.7%</td>
</tr>
</tbody>
</table>
<p>As a sanity check, I compared the models’ results against XGBoost with different feature representations. I used three different feature configurations:</p>
<ol type="1">
<li><p>Averaged: Weighted mean of player stats per team (14 features)</p></li>
<li><p>Summary: Mean, std, min, max of player stats per team (56 features)</p></li>
<li><p>Concatenated: Top-10 players’ stats concatenated (160 features)</p></li>
</ol>
<p>While the first two configurations performed around the same as the other models that I tried (R-squared around 0.2), the concatenation method gave an R-squared of 0.29. This makes some sense. Running XGBoost on these concatenated vectors allows the model to deal with non-linear relationships, which the averaging-based neural net can’t do, without having to learn tens of thousands of parameters, which the attention-based neural net has to do.</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Model</th>
<th>Features</th>
<th>Test R²</th>
<th>Win Accuracy</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>XGBoost (averaged)</td>
<td>14</td>
<td>0.195</td>
<td>65.3%</td>
</tr>
<tr class="even">
<td>XGBoost (summary)</td>
<td>56</td>
<td>0.196</td>
<td>65.2%</td>
</tr>
<tr class="odd">
<td><strong>XGBoost (concat)</strong></td>
<td>160</td>
<td><strong>0.289</strong></td>
<td>65.2%</td>
</tr>
</tbody>
</table>
<p>I didn’t want to give up just yet, and I hypothesized that the game-level averaging by minutes played for each lineup could be obscuring lineup specific effects. So I ran a separate experiment at the lineup level using the same hybrid approach described above. Unfortunately this also didn’t work, with the models having basically no predictive power whatsoever. This is probably because this lineup approach does not account for strength of opponents at all.</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Model</th>
<th>Test R²</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>LineupBaseline</td>
<td>0.0225</td>
</tr>
<tr class="even">
<td>LineupAttention</td>
<td>0.0200</td>
</tr>
</tbody>
</table>
</section>
<section id="interpretation" class="level2">
<h2 class="anchored" data-anchor-id="interpretation">Interpretation</h2>
<p>It’s hard to conclude that lineup chemistry doesn’t exist in the NBA. But this approach didn’t detect it. It’s possible that the efficiency stats I used don’t capture the right signal or that the sample size was too small. It’s also possible that some other kind of attention mechanism would perform better. It could be that synergy is real but too small to be detected when drowned out by individual player quality and noise. I think it’s probably some combination of all of these.</p>
<p>Taking a step back, all of the models I tested had a win accuracy of around 65-67% (except for the models that had to learn embeddings from scratch). This means that while the point differential predictions weren’t the most accurate, they were directionally pretty sound. Indeed, as of January 13, 2026, NBA favorites have a win rate of <a href="https://www.covers.com/sport/basketball/nba/league-trends/seasontodate">64.5%</a>, indicating that the models do have some predictive value. Without considering injuries, rest days, or home court advantage, the models I tested basically matched (they slightly exceeded, but it’s hard to say that’s not just noise) the Vegas oddsmakers’ predictions of who will win games, which I think is a pretty good result.</p>
<p>The code for this project, including scripts for downloading play-by-play data, extracting stats, and training models, is available on <a href="https://github.com/jake-p-bennett/nba-lineup-attention">GitHub</a>.</p>
<p>While I couldn’t get the attention mechanism to model NBA player interactions, it was still fun to play around with these models and learn something new. In the future I’d like to do more work on statistical learning related to NBA stats.</p>


</section>


<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>Though they predicted play outcomes, e.g., made two-point basket, missed three-point attempt, etc.↩︎</p></li>
<li id="fn2"><p>Note that this differs from offensive rating which is the player’s team’s points per 100 possessions when they are on the court.↩︎</p></li>
</ol>
</section></div> ]]></description>
  <category>basketball</category>
  <category>sports</category>
  <guid>https://jake-p-bennett.github.io/blog/posts/nba-lineups/</guid>
  <pubDate>Tue, 13 Jan 2026 08:00:00 GMT</pubDate>
  <media:content url="https://jake-p-bennett.github.io/blog/posts/nba-lineups/jokic.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Time is Money — Even in Chess</title>
  <dc:creator>Jake Bennett</dc:creator>
  <link>https://jake-p-bennett.github.io/blog/posts/time-in-chess/</link>
  <description><![CDATA[ 





<p>As an avid online chess player, it is extremely frustrating to have a winning position only to lose on time. Unfortunately, this happens to me quite frequently. When I watch the best players in the world, however, it seems that they can convert a winning position regardless of how little time is left on their clock (shout out to <a href="https://www.youtube.com/@eric-rosen">Eric Rosen</a>). Generally speaking, it seems that higher rated players are better at managing their time, and are more adept at converting winning positions. I wanted to see if this was borne out in games played on <a href="https://lichess.org">Lichess</a>. This gave me the idea to test out how time impacts the win probability of games across different skill levels.</p>
<p>I built a logistic regression model that predicts outcomes using player ratings, material count, and time remaining. I analyzed bullet games where each player starts with 1 minute, and blitz games where players start with 3 or 5 minutes. I only considered games with no increment (i.e., only considered games where no time is added after each move).</p>
<section id="the-data" class="level2">
<h2 class="anchored" data-anchor-id="the-data">The Data</h2>
<p>With the help of <a href="https://claude.ai/new">Claude</a>, I wrote a python script that downloads games from Lichess’s public <a href="https://database.lichess.org">database</a>. The script takes a player’s Lichess rating<sup>1</sup> range as input, finds players who competed in recent Lichess tournaments within that rating range, and downloads a certain number of games from each of those players (I used a max of 500 games per player in my analysis). I downloaded games from three rating bands: 1000-1499, 1500-1999, and 2000-2499. Generally speaking, the 1000-1499 band contains novice to intermediate players, the 1500-1999 band contains intermediate to advanced players, and the 2000-2499 band contains advanced to master players.</p>
<p>With the games downloaded, I filtered out games with fewer than 10 moves, as it is unlikely that time played much of a role in these games. Then, I sampled a random position from each game, avoiding the first 5 moves and the last 5 moves. Sampling only one position from each games avoids the issue of data from the same game being heavily correlated. Not sampling positions from the first 5 moves reduces inclusion of positions that carry very little signal about the outcome of the game, while not sampling from the last 5 moves helps to reduce the amount of games that are nearly decided.</p>
</section>
<section id="the-model" class="level2">
<h2 class="anchored" data-anchor-id="the-model">The Model</h2>
<p>For each of these rating bands, I trained logistic regression models on 20,000 games each (80% training, 20% test), with a win for white as the response variable and the material difference between players, the rating difference between players, the move number, white’s time ratio (remaining time divided by started time), black’s time ratio, and the difference of these time ratios as the predictor variables. I trained nine models: one for each rating band and time control (bullet, 3-minute blitz, 5-minute blitz).</p>
<p>In blitz games, the rating difference and material difference are both more predictive than the time ratio difference. I think this is partially due to the fact that I downloaded games from Lichess <em>tournaments</em>. Pairing in tournaments works differently than normal pairing on Lichess in that players’ tournament standings are also taken into account. Because of this, a 2000-rated player joining late might face a 1400-rated player on a winning streak. These mismatches are probably inflating the importance of rating difference in the model.</p>
<p>In bullet chess, however, the time ratio difference matters substantially more. This is likely due to the fact that with 1 minute on the clock, every precious second matters. Spending even six seconds on a move removes 10% of your total time. Intuitively it makes sense that less starting time leads to time remaining being more important, which is what the data shows.</p>
<p><img src="https://jake-p-bennett.github.io/blog/posts/time-in-chess/time_coefficient_comparison.png" class="img-fluid" style="width:80.0%"></p>
<p>Looking at the coefficients for the time ratio difference, we can see that my hunch about stronger players being better at converting winning positions under time pressure is not really true. While in bullet chess the time ratio matters less for players in the 2000-2499 range, the coefficient is pretty similar to those for the other rating bands. And in 5-minute blitz chess, the coefficient for the highest rating band is nearly identical to those of the lower rating bands. That is to say, all else equal, time pressure appears to affect all players in approximately the same way.</p>
<p>Another interesting finding from this analysis is that in 5+0 blitz, the coefficient for material balance decreases at higher ratings, but the opposite is true for bullet chess (in 3+0, it is around the same for all rating bands). This indicates that the material difference matters more for stronger players in faster games, but less in slower games. In bullet games, perhaps this speaks to strong players’ offensive abilities. Up on material, they can press their advantage relentlessly and even somewhat recklessly given the quick nature of the games. In blitz games, this might be a sign of strong players’ defense. With more time to spare, they may be able to find ways to hold on even when down a pawn or two.</p>
</section>
<section id="how-good-is-the-model" class="level2">
<h2 class="anchored" data-anchor-id="how-good-is-the-model">How Good is the Model?</h2>
<p>To analyze the model itself, I performed a calibration analysis and an error analysis. For the calibration analysis, I compared predicted probabilities to actual win rates and tracked the distribution of predictions. Interestingly, the predictions for the 1000-1499 and 1500-1999 rating bands appear to be roughly normal, while the predictions for the 2000-2499 rating band have more predictions in the 0 to 0.1 and 0.9 to 1 range. This may be because stronger players are better at converting winning positions. In general, the model is well-calibrated across time controls and rating bands, with all <a href="https://en.wikipedia.org/wiki/Brier_score">Brier scores</a> less than 0.2. In other words, when the model predicted a 70% chance of white winning, white actually won about 70% of the time (same for 80%, 90%, or any predicted probability).</p>
<p>For the error analysis, I inspected several games where the model was very confident but ended up being wrong. While the most confident predictions generally come from games where there is a large rating gap (because of the size of the coefficient), it doesn’t appear that there is one particular type of game or position that the model consistently gets very wrong. For example, in this 3-minute blitz <a href="https://lichess.org/nhAPBbFq">game</a>, for the sampled position, black is up a bishop, up on time, and rated 440 points higher than white. The model predicts a 3.8% chance of white winning.</p>
<p><img src="https://jake-p-bennett.github.io/blog/posts/time-in-chess/sample_position.png" class="img-fluid" style="width:80.0%"></p>
<p>However, just a few moves later, black misses a fork that blunders the black queen, which white finds. Black resigned.</p>
<p><img src="https://jake-p-bennett.github.io/blog/posts/time-in-chess/final_position.png" class="img-fluid" style="width:80.0%"></p>
<p>In another <a href="https://lichess.org/346b6LS1#68">blitz game</a>, white is up the exchange (i.e., has a rook in exchange for a knight) as well as two extra pawns, and is rated 399 points higher than black. On top of that, black has 11 seconds left on their clock. The model gives white a 95.6% chance of winning.</p>
<p><img src="https://jake-p-bennett.github.io/blog/posts/time-in-chess/sample_position2.png" class="img-fluid" style="width:80.0%"></p>
<p>Black then proceeds to move extremely quickly, causing white to run out of time and lose the game.</p>
<p><img src="https://jake-p-bennett.github.io/blog/posts/time-in-chess/final_position2.png" class="img-fluid" style="width:80.0%"></p>
<p>As you might expect, many of the errors from the bullet games are due to the favored side running out of time. One egregious error came from this <a href="https://lichess.org/82yfrcRM#59">game</a> where white is completely crushing black, as we might expect given the 674 point rating gap. The problem is, white has one second left. Despite this, the model gives white a 99.4% chance to win, with the rating difference and material advantage overpowering the time situation. Unsurprisingly, white lost on time.</p>
<p><img src="https://jake-p-bennett.github.io/blog/posts/time-in-chess/sample_position3.png" class="img-fluid" style="width:80.0%"></p>
</section>
<section id="whats-next" class="level2">
<h2 class="anchored" data-anchor-id="whats-next">What’s Next?</h2>
<p>It would be interesting to add <a href="https://en.wikipedia.org/wiki/Stockfish_(chess)">Stockfish</a> evaluation as a feature. At first glance we might think that engine evaluations would dominate the win probability, but given the inclusion of games with huge rating differences, I’m not so sure. One thing I did not consider for my analysis was correlation between features. Down the road this may be worth looking into, as multicollinearity may impact the interpretation of the coefficients.</p>
<p>The code for this analysis, including scripts for downloading games, extracting features, and training models, is available on <a href="https://github.com/jake-p-bennett/chess-win-probability">GitHub</a>.</p>
<p>In sum, my analysis found that time pressure affects all players pretty equally, especially in 5+0 blitz chess. While World Chess Champion <a href="https://en.wikipedia.org/wiki/Emanuel_Lasker">Emanuel Lasker</a> supposedly said, “When you see a good move, look for a better one,” in blitz chess, it’s probably worth it to just play the good move.</p>


</section>


<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>Lichess uses the <a href="https://www.glicko.net/glicko/glicko2.pdf">Glicko-2 system</a>, though the term <a href="https://en.wikipedia.org/wiki/Elo_rating_system">ELO</a> is still widely used to denote a player’s strength. This analysis uses Glicko-2 ratings.↩︎</p></li>
</ol>
</section></div> ]]></description>
  <category>chess</category>
  <guid>https://jake-p-bennett.github.io/blog/posts/time-in-chess/</guid>
  <pubDate>Mon, 05 Jan 2026 08:00:00 GMT</pubDate>
  <media:content url="https://jake-p-bennett.github.io/blog/posts/time-in-chess/clock.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Betting on The Athletic’s NFL Projections</title>
  <dc:creator>Jake Bennett</dc:creator>
  <link>https://jake-p-bennett.github.io/blog/posts/nfl-betting/</link>
  <description><![CDATA[ 





<p>During the 2024-2025 NFL season, The Athletic maintained an NFL projections <a href="https://www.nytimes.com/athletic/5698572/2025/02/09/nfl-playoffs-projections-odds/?page=games&amp;week=1">webpage</a> that contained forecasts for each regular season and playoff game. The projections included forecasted points spreads, and I was curious to see how these forecasts compared to the Las Vegas spreads and the actual game outcomes. I back-tested a simple betting strategy:</p>
<ol type="1">
<li><p>When The Athletic’s spread is greater than the Vegas spread, bet on the favorite.</p></li>
<li><p>When The Athletic’s spread is less than the Vegas spread, bet on the underdog.</p></li>
<li><p>If the spreads are the same, do not place a bet.</p></li>
</ol>
<p>The strategy only makes spread bets (i.e., no moneyline bets), and assumes -110 odds (wagering $110 to win $100).</p>
<p>Of the 285 NFL games in the 2024-2025 season (regular season and playoffs), there were 239 games where The Athletic’s spread did not match the Vegas spread. On average, The Athletic’s spreads differed from the actual game outcome by 9.75 points, while Vegas’s spreads differed by 9.66 points. The median differences for The Athletic and Vegas were 7.5 points and 7 points, respectively. These are minimal differences, to be sure, but the Vegas lines were more accurate for the 2024-2025 season.</p>
<p>Unfortunately, the betting strategy described above does not give us an edge. Assuming bets of $110, employing the strategy would have lost $1,360 for a return of -5.17%. In fact, using the complete opposite strategy would have lost $940 for a return of -3.58%, which is better than the -4.55% we would expect from winning half of our bets.</p>
<p>Then I wondered if The Athletic’s spread forecasts were better for a particular “direction” of spread difference. That is to say, what if we bet only on games where The Athletic had the favorite favored by more? What if we bet only on games where The Athletic had the favorite favored by less?</p>
<p>It turns out that betting only on games where The Athletic had the favorite favored by more than Vegas would have been profitable to varying degrees, depending on what threshold of spread difference is used.</p>
<p><img src="https://jake-p-bennett.github.io/blog/posts/nfl-betting/return_table.png" class="img-fluid" style="width:70.0%" data-fig_align="right"></p>
<p>The same cannot be said for games where The Athletic had the favorite favored by less:</p>
<p><img src="https://jake-p-bennett.github.io/blog/posts/nfl-betting/return_table2.png" class="img-fluid" style="width:70.0%"></p>
<p>The Athletic is still publishing weekly spread forecasts for the current 2025-2026 season (e.g., here is the link for <a href="https://www.nytimes.com/athletic/6684060/2025/10/02/nfl-week-5-projected-scores-model-predicts-point-spreads-totals/">Week 5</a>). I will be monitoring these projections to see if they fare better or worse than last year’s.</p>
<p>If you are curious to see more, you can download the <a href="https://github.com/jake-p-bennett/blog/blob/main/posts/NFL%20Betting/notebooks/nfl-notebook.ipynb">analysis workbook</a> and the <a href="https://github.com/jake-p-bennett/blog/tree/main/posts/NFL%20Betting/data">data</a> for this post.</p>



 ]]></description>
  <category>football</category>
  <category>sports</category>
  <guid>https://jake-p-bennett.github.io/blog/posts/nfl-betting/</guid>
  <pubDate>Sat, 04 Oct 2025 07:00:00 GMT</pubDate>
  <media:content url="https://jake-p-bennett.github.io/blog/posts/nfl-betting/allen.jpeg" medium="image" type="image/jpeg"/>
</item>
</channel>
</rss>

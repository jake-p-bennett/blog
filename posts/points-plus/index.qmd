---
title: "Jarvis, Who's the Best Scorer in the NBA?"
subtitle: "Quickly building an NBA dashboard with Claude Code"
excerpt: False
author: "Jake Bennett"
format: html
editor: visual
categories: [basketball, sports, ai]
date: 2026-2-11
image: "jarvis.webp"
---

While I have integrated some AI tools into my everyday life, I have always found the hype around [vibe coding](https://en.wikipedia.org/wiki/Vibe_coding) to be overblown. I have used LLMs to generate code, but whenever I've tried to build a whole app or website, it's failed. For example, a month ago I tried to build a simple NFL playoff bracket that my friends and I could fill out -- nothing too complicated, just a bracket set up with certain scoring rules and a leaderboard to see where people stand. I tried to have Anthropic's [Claude Opus 4.5](https://www.anthropic.com/news/claude-opus-4-5) build the website, but it never got off the ground. The clicking mechanisms were broken, the bracket formatting was terrible, and Claude decided to make the scoring variable cumulative -- any time you clicked on a team, your score would increase indefinitely, with no way to undo the additions to the score. After trying to prompt Claude to edit the site for an hour or so, I gave up, reaffirmed in my diagnosis that the vibe coding hype was far from reality, even for simple applications.

A few days ago while scrolling through Twitter (I still refuse to call it X), I came across an essay titled [Something Big is Happening](https://x.com/mattshumer_/status/2021256989876109403) by Matt Shumer. Generally I don't read Twitter essays since I find they tend to contain a lot of [slop](https://en.wikipedia.org/wiki/AI_slop), but the algorithm kept insisting on putting this one on my feed. I finally relented and gave it a read after [Matt Yglesias](https://en.wikipedia.org/wiki/Matthew_Yglesias) [tweeted](https://x.com/mattyglesias/status/2021354578407772287) about it, since Yglesias is far enough removed from the Twitter-tech-echo-chamber.

The essay describes how much frontier models like OpenAI's ChatGPT and Anthropic's Claude have advanced over the past year, and even over the past week. Shumer goes on to argue that everyone employed in a type of 'knowledge work' (e.g. software engineering, legal work, financial analysis) is at risk of being displaced by AI, and gives recommendations for what to do to shield yourself from this upheaval. I was less interested in Shumer's macroeconomic predictions[^1] and more interested in one of his claims:

[^1]: And as always, it's worth thinking about if Shumer has anything to gain from hyping AI. His [website](https://shumer.dev/about) makes clear that he is the founder of an AI company and invests in other AI companies.

> Let me give you an example so you can understand what this actually looks like in practice. I'll tell the AI: "I want to build this app. Here's what it should do, here's roughly what it should look like. Figure out the user flow, the design, all of it." And it does. It writes tens of thousands of lines of code. Then, and this is the part that would have been unthinkable a year ago, it opens the app itself. It clicks through the buttons. It tests the features. It uses the app the way a person would. If it doesn't like how something looks or feels, it goes back and changes it, on its own. It iterates, like a developer would, fixing and refining until it's satisfied.

Shumer's essay makes it sound like one can simply ask a supremely competent AI to put together a project, like Tony Stark working with [J.A.R.V.I.S.](https://en.wikipedia.org/wiki/J.A.R.V.I.S.) As I mentioned, this was far from my experience with LLMs in the past, even as recently as around a month ago. I was curious to see if models really have gotten that much better since then.

To test this, I decided to see if Anthropic's newly released [Opus 4.6](https://www.anthropic.com/news/claude-opus-4-6) model could build a simple NBA dashboard website that I had been thinking about. My idea was to create a stat called 'Points+', which mimics baseball stats like [OPS+](https://www.mlb.com/glossary/advanced-stats/on-base-plus-slugging-plus) and [wRC+](https://www.mlb.com/glossary/advanced-stats/weighted-runs-created-plus) that account for strength of opponent and scale to the league's average (centered at 100).

I created a folder on my computer called `nba-dashboard/`, gave [Claude Code](https://code.claude.com/docs/en/overview) access to the folder, and then created a `CLAUDE.md` file with the following instructions:

> I want you to build an NBA dashboard that tracks a new individual stat called 'Points+' for NBA players in the current (2025-2026) NBA season. Points+ is conceptually similar to OPS+ or wRC+ in baseball -- it measures points per game compared to league average, adjusting for opponent difficulty (and maybe some other things). So 100 would be an average scorer, and 120 would be a scorer who is 20% better than league average.
>
> The deliverable of this is going to be a website that shows the top 50 players in terms of Points+, and it also will have a search option to look up specific players. Maybe there will be some cool visualizations on there too, if you're up for it.
>
> You have complete creative freedom in how you build this website. You'll have to figure out how to obtain the data, how to calculate the stat for each player, and how to build the webpage.
>
> Eventually I'd like this website to automatically download data for each game (maybe the morning of every day) since the NBA season is currently going on. But right now let's focus on getting the site up and running with an 'as-of' date of 2/10/26.
>
> If you have any clarifying questions, you will ask me. You are to test things out as you go. The first time you show me a prototype of the website, I want it to work. I want to be able to click around in it without things breaking.

Claude worked for 8 minutes, and to my surprise, presented me with a working prototype. It had done everything I asked for: it obtained the data, defined requirements for which players qualify, synthesized the stats into Points+, and created a pretty aesthetically pleasing website. There were a few cosmetic things that I asked it to change (some text was too dark against the background, main summary table was too wide) and a few small technical changes I had it make (the histogram originally did not include the top players, sorting by Points+ showed that ties were handled randomly), but overall it got the website working on the first try. I even had it walk me through how to deploy it to a domain name that I purchased. I wanted to make the site dynamically update with new data every day, and it built that into the site too. The whole process took around 90 minutes.

I'm not sure anyone knows what the future of AI-integrated work looks like. But it does seem that these models are now at a point where they can spin up a personal project with loosely defined requirements extremely quickly. Of course this project is simple -- there is no user login, no security concerns, no complicated database management. Even so, I was impressed by the model's ability to get a working site in front of me so quickly, especially given how miserably my previous attempts at vibe coding had failed.

You can check out the live site at [nbapointsplus.com](https://nbapointsplus.com), and if you're curious to see the technical approach that Claude took, check out the GitHub [repo](https://github.com/jake-p-bennett/nba-dashboard).

**UPDATE (February 13, 2026):** As I mentioned, I want the site to dynamically update with new data every day, and Claude tried to integrate that. It has not worked over the past two days, and I've had to manually run the data fetching script and push it to the site. Claude had recommended a [GitHub action](https://github.com/features/actions), but when I asked why it failed, it told me

> The issue is clear: stats.nba.com is timing out all requests from GitHub Actions runners (all 3 attempts hit the 30s timeout). This is a known problem — NBA.com rate-limits/blocks requests from cloud datacenter IPs (like GitHub's runners), and it works inconsistently.

Because my IP address isn't from a cloud datacenter, I don't get timed out when I make a request from my computer. So Claude's new recommendation was to set up a scheduled run of the data update with launchd[https://en.wikipedia.org/wiki/Launchd]. That also didn't work, to which Claude replied,

> The issue is clear. The error log says:
>
> Operation not permitted
>
> The script itself is fine — it ran successfully on Feb 12. But the next scheduled run failed because macOS is blocking it. The shell script doesn't have execute permission granted by macOS's security system (this is separate from Unix file permissions).

So now Claude has wrapped the script in a 'tiny wrapper binary', and I've granted full-disk access to the wrapper. Supposedly this will allow the script to run tomorrow morning. We shall see!

I think these oversights/omissions show that Claude isn't perfect at this kind of thing. To be fair, I'm not a software engineer and I don't know much about GitHub actions, launchd, or script wrappers. If I did, maybe I could have improved my prompts to ensure that these issues didn't pop up. Asking the right questions and knowing where things might break will continue to be a valuable skill when working with these models.

